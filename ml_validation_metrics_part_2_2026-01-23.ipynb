{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07928fe3",
   "metadata": {},
   "source": [
    "### ML Validation Metrics. Part 2\n",
    "#### Date: 2026-01-23\n",
    "\n",
    "**Topics:**\n",
    "> 1. Causality\n",
    "> 2. Confounders\n",
    "> 3. Calibration\n",
    "> 4. LogLoss\n",
    "\n",
    "**Materials:**\n",
    "> 1. \n",
    "> 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff946ccc",
   "metadata": {},
   "source": [
    "#### Causality\n",
    "ML-модель вміє передбачати, але НЕ вміє доводити вплив дії\n",
    "\n",
    "**Prediction:** спрогнозувати proba для churn  \n",
    "**Intervention:** запрононувати знижку \n",
    "\n",
    "##### prediction != intervention\n",
    "\n",
    "ML-модель виявляє:\n",
    "> транзакції з високою ймовірністю fraud\n",
    "\n",
    "Помилковий висновок:\n",
    "> Якщо ми їх заблокуємо — ми зменшимо fraud\n",
    "\n",
    "Модель не знає, що було б:\n",
    "> якби ми не заблокували \\\n",
    "> якби ми заблокували інакше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a5d4e",
   "metadata": {},
   "source": [
    "#### Confounders\n",
    "\n",
    "Фактор, який впливає і на ознаку, і на результат\n",
    "та створює хибне враження причинності\n",
    "\n",
    "\n",
    "**Спостереження з даних:**\n",
    "> користувачі зі знижками частіше йдуть\n",
    "\n",
    "**Хибний висновок:**\n",
    "> Знижки збільшують churn\n",
    "\n",
    "**Реальність:**\n",
    "> знижки дають тим, хто вже хотів піти\n",
    "\n",
    "намір піти — confounder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d463c",
   "metadata": {},
   "source": [
    "#### Calibration \n",
    "\n",
    "**Модель видає:** p = 0.8, 80% імовірність -> можна діяти впевнено\n",
    "\n",
    "> серед усіх прогнозів p~0.8 \\\n",
    "> реально fraud трапляється у 50% випадків \\\n",
    "> модель переоцінює ризик\n",
    "\n",
    "\n",
    "Якщо модель каже p = 0.3,\n",
    "то подія відбувається приблизно у 30% випадків\n",
    "\n",
    "> бізнес приймає рішення по порогах \\\n",
    "> пороги базуються на p \\\n",
    "> якщо p бреше -> рішення хаотичні"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f529a1ae",
   "metadata": {},
   "source": [
    "##### LogLoss - індекатор калібровки\n",
    "наскільки сильно модель карається за впевнені, але неправильні прогнози\n",
    "\n",
    "Якщо дві моделі мають схожий PR-AUC, але одна має нижчий LogLoss — її ймовірностям можна більше довіряти"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb034229",
   "metadata": {},
   "source": [
    "> ML -> оцінює ризик \\\n",
    "> Calibration -> робить ризик чесним \\\n",
    "> Policy -> перетворює ризик у дію \\\n",
    "> Causality -> не дозволяє брехати про ефект\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8530097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, log_loss,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca9a7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: \"\\c\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\c\"? A raw string is also an option.\n",
      "<>:1: SyntaxWarning: \"\\c\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\c\"? A raw string is also an option.\n",
      "C:\\Users\\Daryna\\AppData\\Local\\Temp\\ipykernel_4120\\704675752.py:1: SyntaxWarning: \"\\c\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\c\"? A raw string is also an option.\n",
      "  df = pd.read_csv(\"data\\creditcard.csv\") # !! требі змінити на свій шлях до файлу !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top missing columns:\n",
      "Time    0.0\n",
      "V1      0.0\n",
      "V2      0.0\n",
      "V3      0.0\n",
      "V4      0.0\n",
      "V5      0.0\n",
      "V6      0.0\n",
      "V7      0.0\n",
      "V8      0.0\n",
      "V9      0.0\n",
      "dtype: float64\n",
      "\n",
      "Class counts:\n",
      " Class\n",
      "'0'    284315\n",
      "'1'       492\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class ratio:\n",
      " Class\n",
      "'0'    0.998273\n",
      "'1'    0.001727\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data\\creditcard.csv\") # !! требі змінити на свій шлях до файлу !!\n",
    "\n",
    "missing_rate = df.isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nTop missing columns:\")\n",
    "print(missing_rate.head(10))\n",
    "\n",
    "\n",
    "class_counts = df[\"Class\"].value_counts()\n",
    "class_ratio = df[\"Class\"].value_counts(normalize=True)\n",
    "\n",
    "print(\"\\nClass counts:\\n\", class_counts)\n",
    "print(\"\\nClass ratio:\\n\", class_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d90c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] = df['Class'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651ec9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Class\"])\n",
    "y = df[\"Class\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be8602b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87497108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(y_true: pd.Series, y_proba: np.ndarray, k_frac: float) -> float:\n",
    "    n = len(y_true)\n",
    "    k = max(1, int(n * k_frac)) \n",
    "\n",
    "    top_idx = np.argsort(y_proba)[::-1][:k] # 10 fraud -> 4 \n",
    "    fraud_in_top = y_true.iloc[top_idx].sum()\n",
    "\n",
    "    total_fraud = y_true.sum()\n",
    "\n",
    "    return fraud_in_top / max(1, total_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af96725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all(y_true: pd.Series, y_proba: np.ndarray, threshold: float, k_fracs=(0.001, 0.005, 0.01)) -> dict:\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    out = {\n",
    "        \"threshold\": threshold,\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"ROC-AUC\": roc_auc_score(y_true, y_proba),\n",
    "        \"PR-AUC\": average_precision_score(y_true, y_proba),\n",
    "        \"LogLoss\": log_loss(y_true, y_proba, labels=[0, 1]),\n",
    "        \"ConfusionMatrix\": confusion_matrix(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "    for kf in k_fracs:\n",
    "        out[f\"Recall@{kf*100:.2f}%\"] = recall_at_k(y_true, y_proba, k_frac=kf)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4f05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(title: str, metrics: dict):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(title)\n",
    "    print(\"=\"*60)\n",
    "    for k, v in metrics.items():\n",
    "        if k == \"ConfusionMatrix\":\n",
    "            continue\n",
    "        print(f\"{k:>14}: {v}\")\n",
    "\n",
    "    cm = metrics[\"ConfusionMatrix\"]\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(\"\\nConfusion Matrix [[TN FP],[FN TP]]:\")\n",
    "    print(cm)\n",
    "    print(f\"TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aeb7aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LogReg threshold = 0.5\n",
      "============================================================\n",
      "     threshold: 0.5\n",
      "     Precision: 0.06097560975609756\n",
      "        Recall: 0.9183673469387755\n",
      "            F1: 0.11435832274459974\n",
      "       ROC-AUC: 0.9720834996210077\n",
      "        PR-AUC: 0.7189705771419241\n",
      "       LogLoss: 0.11219568508746044\n",
      "  Recall@0.10%: 0.45918367346938777\n",
      "  Recall@0.50%: 0.8877551020408163\n",
      "  Recall@1.00%: 0.8979591836734694\n",
      "\n",
      "Confusion Matrix [[TN FP],[FN TP]]:\n",
      "[[55478  1386]\n",
      " [    8    90]]\n",
      "TN=55478, FP=1386, FN=8, TP=90\n"
     ]
    }
   ],
   "source": [
    "lr = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),  \n",
    "    (\"model\", LogisticRegression(\n",
    "        class_weight = \"balanced\",   \n",
    "        max_iter = 2000\n",
    "    ))\n",
    "])\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "proba_lr = lr.predict_proba(X_test)[:, 1]\n",
    "res_lr_05 = evaluate_all(y_test, proba_lr, threshold=0.5)\n",
    "print_eval(\"LogReg threshold = 0.5\", res_lr_05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7490209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RandomForest threshold = 0.5\n",
      "============================================================\n",
      "     threshold: 0.5\n",
      "     Precision: 0.961038961038961\n",
      "        Recall: 0.7551020408163265\n",
      "            F1: 0.8457142857142858\n",
      "       ROC-AUC: 0.9561641166033098\n",
      "        PR-AUC: 0.8635428629090862\n",
      "       LogLoss: 0.006316197456721261\n",
      "  Recall@0.10%: 0.5510204081632653\n",
      "  Recall@0.50%: 0.8979591836734694\n",
      "  Recall@1.00%: 0.8979591836734694\n",
      "\n",
      "Confusion Matrix [[TN FP],[FN TP]]:\n",
      "[[56861     3]\n",
      " [   24    74]]\n",
      "TN=56861, FP=3, FN=24, TP=74\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators = 400,\n",
    "    random_state = RANDOM_STATE,\n",
    "    n_jobs = -1,\n",
    "    class_weight = \"balanced_subsample\"  \n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "res_rf_05 = evaluate_all(y_test, proba_rf, threshold=0.5)\n",
    "print_eval(\"RandomForest threshold = 0.5\", res_rf_05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab02505",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": [300, 500, 800],\n",
    "    \"max_depth\": [None, 8, 12, 16, 20],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced_subsample\"\n",
    "    ),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,                      \n",
    "    scoring=\"average_precision\",     \n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuned = search.best_estimator_\n",
    "print(\"\\nBest params:\", search.best_params_)\n",
    "print(\"Best CV PR-AUC:\", search.best_score_)\n",
    "\n",
    "proba_rf_tuned = rf_tuned.predict_proba(X_test)[:, 1]\n",
    "res_rf_tuned_05 = evaluate_all(y_test, proba_rf_tuned, threshold=0.5)\n",
    "print_eval(\"RandomForest (tuned) @ threshold=0.5\", res_rf_tuned_05)\n",
    "\n",
    "print(\"\\nRecall@0.5% (RF tuned):\", recall_at_k(y_test, proba_rf_tuned, 0.005))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c848c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cal = CalibratedClassifierCV(\n",
    "    estimator=rf_tuned,   \n",
    "    method=\"isotonic\",\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "rf_cal.fit(X_train, y_train)\n",
    "proba_rf_cal = rf_cal.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "res_before = evaluate_all(y_test, proba_rf_tuned, threshold=0.2)\n",
    "res_after  = evaluate_all(y_test, proba_rf_cal, threshold=0.2)\n",
    "\n",
    "print_eval(\"RF tuned BEFORE calibration  threshold=0.2\", res_before)\n",
    "print_eval(\"RF tuned AFTER  calibration  threshold=0.2\", res_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c2e242e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proba_rf_tuned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 18\u001b[0m plot_calibration(y_test, \u001b[43mproba_rf_tuned\u001b[49m, proba_rf_cal, n_bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'proba_rf_tuned' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_calibration(y_true, prob_uncal, prob_cal, n_bins=10):\n",
    "    t_uncal, p_uncal = calibration_curve(y_true, prob_uncal, n_bins=n_bins, strategy=\"uniform\")\n",
    "    t_cal,   p_cal   = calibration_curve(y_true, prob_cal,   n_bins=n_bins, strategy=\"uniform\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "\n",
    "    plt.plot(p_uncal, t_uncal, marker=\"o\", label=\"Before calibration\")\n",
    "\n",
    "    plt.plot(p_cal, t_cal, marker=\"o\", label=\"After calibration\")\n",
    "\n",
    "    plt.xlabel(\"Середня передбачена ймовірність (p)\")\n",
    "    plt.ylabel(\"Реальна частота fraud\")\n",
    "    plt.title(\"Calibration curve (reliability)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_calibration(y_test, proba_rf_tuned, proba_rf_cal, n_bins=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e071b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraud_policy(p: float) -> str:\n",
    "    if p >= 0.90:\n",
    "        return \"AUTO_BLOCK_or_2FA\"\n",
    "    elif p >= 0.40:\n",
    "        return \"MANUAL_REVIEW\"\n",
    "    else:\n",
    "        return \"ALLOW\"\n",
    "\n",
    "actions = pd.Series(proba_rf_cal).apply(fraud_policy)\n",
    "\n",
    "print(\"\\nAction distribution:\")\n",
    "print(actions.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6b4db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
